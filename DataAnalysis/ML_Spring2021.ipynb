{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f09f50",
   "metadata": {},
   "source": [
    "## 1. Streaming K-means\n",
    "\n",
    "In this problem, we consider how to extend the k-means algorithm to process streaming data. The standard k-means algorithm loads all data points into memory. In practice, data may come in a stream, such that they are sequentially processed and dropped. The advantage of streaming algorithms is in processing data that cannot fit into the memory.\n",
    "Now consider how to extend the k-means algorithm to the streaming version. \n",
    "\n",
    "Suppose that there are $k$ clusters. The cluster centers are randomly initialized. Once the processor receives a data point $x \\in R_d$, it does the following: 1) Find the cluster whose center is the closest to $x$ (in Euclidean distance), then add x to the cluster; 2) Adjust the cluster center so that it equals the mean of all cluster members. The algorithm outputs the $k$ cluster centers after processing all data points in the stream. According to the above algorithm specification, complete the streaming algorithm for k-means:\n",
    "\n",
    "(a) List the variables that are stored in the memory and their initial values. Which variables should be the output of the algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c33670",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "To design a streaming version of the k-means algorithm, we must first identify the essential variables and their initial states. The primary objective is to minimize memory usage while processing the data points coming in a stream. Here's how we can set up the variables:\n",
    "\n",
    "1. **Number of Clusters, $k$**: This is a predefined constant indicating the number of clusters to form.\n",
    "\n",
    "2. **Cluster Centers, $C = \\{c_1, c_2, ..., c_k\\}$**: These are vectors in $\\mathbb{R}^d$. Initially, they are randomly initialized. Each $c_i$ represents the center of the $i$-th cluster.\n",
    "\n",
    "3. **Counters, $N = \\{n_1, n_2, ..., n_k\\}$**: A set of integers representing the number of data points in each cluster. Initially, $n_i = 0$ for all $i$.\n",
    "\n",
    "4. **Sum of Points in Each Cluster, $S = \\{s_1, s_2, ..., s_k\\}$**: These are vectors in $\\mathbb{R}^d$. Each $s_i$ represents the cumulative sum of all points in the $i$-th cluster. Initially, $s_i = \\vec{0}$ (the zero vector in $\\mathbb{R}^d$) for all $i$.\n",
    "\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db83ce1",
   "metadata": {},
   "source": [
    "(b) When the processor receives a data point $x$, state the updates that are made on the variables.\n",
    "\n",
    "\n",
    "<div style=\"color:blue\">\n",
    "    \n",
    "When a new data point $x \\in \\mathbb{R}^d$ arrives:\n",
    "  1. Find the closest cluster center to $x$. Denote this cluster as $j$, where $j = \\text{argmin}_i \\| x - c_i \\|$.\n",
    "  2. Update the sum for cluster $j$: $s_j = s_j + x$.\n",
    "  3. Increment the counter for cluster $j$: $n_j = n_j + 1$.\n",
    "  4. Update the center of cluster $j$: $c_j = \\frac{s_j}{n_j}$.\n",
    "\n",
    "The output of the algorithm after processing all data points in the stream would be the final cluster centers $C = \\{c_1, c_2, ..., c_k\\}$.\n",
    "\n",
    "This approach ensures that the entire dataset does not need to be stored in memory, making it feasible for streaming data. Only the cluster centers, the count, and the sum of points in each cluster are retained.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb6e1f",
   "metadata": {},
   "source": [
    "(c) In each iteration, suppose the processor receives a data point x along with its weight w > 0. We want the cluster center to be the weighted average of all cluster members. How do you modify the updates in question (b) to process weighted data?\n",
    "\n",
    "\n",
    "<div style=\"color:blue\">\n",
    "    \n",
    "Step 2 and 3 needs to be updated. Also, $n_j$ now tracks the total weight of the points in cluster $j$, instead of the total number of points assigned to cluster $j$\n",
    "    \n",
    "1. Find the closest cluster center to $x$. Denote this cluster as $j$, where $j = \\text{argmin}_i \\| x - c_i \\|$.\n",
    "2. Update the sum for cluster $j$: $s_j = s_j + wx$.\n",
    "3. Increment the counter for cluster $j$: $n_j = n_j + w$.\n",
    "4. Update the center of cluster $j$: $c_j = \\frac{s_j}{n_j}$.\n",
    "\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea5ceac",
   "metadata": {},
   "source": [
    "## 2. Cars and Clusters\n",
    "\n",
    "(a) Imagine $n$ cars, each of which travels at a different maximum speed. Initially, the cars are queued up in uniform random order at the starting point of a semi-infinite, one lane highway. Each car drives at the minimum of its maximum speed and the speed at which the car in front of it is driving. The cars will form 'clumps'/clusters. What is the expected number of clumps? Prove your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab4aea",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "**1. Define variables:**\n",
    "\n",
    "- Let $n$ represent the number of cars.\n",
    "- Let $C_n$ represent the expected number of clumps for $n$ cars.\n",
    "\n",
    "**2. Establish a base case:**\n",
    "\n",
    "- If there's only one car ($n = 1$), there's only one clump. So, $C_1 = 1$.\n",
    "\n",
    "**3. Apply a recursive approach:**\n",
    "\n",
    "- Consider adding the $n$-th car to $n-1$ cars already on the highway.\n",
    "- The $n$-th car either forms a new clump (if it's the slowest) or joins an existing clump.\n",
    "- The probability of it being the slowest is $\\frac{1}{n}$.\n",
    "\n",
    "**4. Formulate the recursive relation:**\n",
    "\n",
    "$C_n = C_{n-1} + \\frac{1}{n}$\n",
    "\n",
    "**5. Solve the recursion:**\n",
    "\n",
    "- Expand the recursion:\n",
    "\n",
    "$C_n = C_{n-2} + \\frac{1}{n-1} + \\frac{1}{n} = C_{n-3} + \\frac{1}{n-2} + \\frac{1}{n-1} + \\frac{1}{n} = ... = C_1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n}$\n",
    "\n",
    "- Substitute $C_1 = 1$:\n",
    "\n",
    "$C_n = 1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n}$\n",
    "\n",
    "**6. Recognize the harmonic series:**\n",
    "\n",
    "- The sum $1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n}$ is the $n$-th harmonic number, denoted as $H_n$.\n",
    "\n",
    "**7. Conclusion:**\n",
    "\n",
    "- The expected number of clumps is $C_n = H_n$, the $n$-th harmonic number.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e01fc",
   "metadata": {},
   "source": [
    "(b) Consider the following random graph model with clustering. For n nodes, we have $P(n, 3)$ distinct ‘triplets’. For each triplet, with independent probability $p$ we connect the nodes belonging to this triplet in the graph using three edges to form a triangle, where \n",
    "\n",
    "$$p = \\frac{c}{P(n-1, 2)}$$\n",
    "\n",
    "$c$ is a constant. Assume $n$ is very large. Show that the expected degree of a node in this graph model is $2c$.\n",
    "\n",
    "<div style=\"color:blue\">\n",
    "\n",
    "$$ E[\\text{Total #Edges}] = P(n-1, 2) \\times p \\times 3 = \\frac{cn}{3} \\times 3 = cn$$\n",
    "$$ E[\\text{Node Degree}] = 2 \\times E[\\text{Total \\# Edges}] / n = 2c$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc620a35",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machine\n",
    "\n",
    "Given 2-dimensional input data points S1 = {(1, 4), (1, 5), (2, 4), (2, 5), (3, 3)}, S2 = {(3,2),(3,1),(4,1),(5,1),(6,1),(6,2)},where $S_1$ has the data points from the positive class and $S_2$ has data points from the negative class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d262f35",
   "metadata": {},
   "source": [
    "(a) Suppose you are using a linear SVM with no provision for noise (i.e. a Linear SVM that is trying to maximize its margin while ensuring all data points are on their correct sides of the margin). Draw three lines on the above diagram, showing classification boundary and the two sides of the margin. Circle the support vector(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a820d35",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f661e9",
   "metadata": {},
   "source": [
    "(b) Using the familiar Linear SVM classifier notation of the classifier sign(wT x + b), calculate the values of w and b learned for part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97f2bb",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "The learned parameters using the Linear SVM classifier are:\n",
    "\n",
    "$w = (0, 2)$\n",
    "$b = -5$\n",
    "\n",
    "So the classifier can be described by the equation $\\text{sign}(w^T x + b)$, which in this case is $\\text{sign}([0, 2] \\cdot x - 5)$.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565085a",
   "metadata": {},
   "source": [
    "\n",
    "(c) Assume you are using a noise-tolerant Linear SVM which tries to optimize \n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\min _{w, b, \\epsilon} \\frac{1}{2} \\boldsymbol{w}^T \\boldsymbol{w}+C \\Sigma_i \\epsilon^i \\\\\n",
    "\\text { s.t. } y_i\\left(\\boldsymbol{w}^T \\boldsymbol{x}^i+b\\right) \\geq 1-\\epsilon^i, \\epsilon^i \\geq 0, \\forall i\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "Question: is it possible to invent a dataset and a positive value of $C$ in which the dataset is linearly separable but the linear SVM classifier would never the less misclassify at least one training point? If it is possible to invent such an example, please sketch the example and suggest a value for $C$. If it is not possible, explain why not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dce6ec",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "It is possible\n",
    "    \n",
    "When $C$ is large, the SVM model tries to minimize the slack variables \\( \\epsilon^i \\) as much as possible to reduce misclassification. In a linearly separable case, it is possible to achieve \\( \\epsilon^i = 0 \\) for all \\( i \\), leading to no misclassification.\n",
    "\n",
    "A small value of $C$ makes the SVM more tolerant to violations (misclassifications). Even if the data is linearly separable, the model might choose to misclassify some points if it leads to a simpler decision boundary (smaller $\\boldsymbol{w}$). This happens because the penalty for misclassification is lower, and the optimization might find a solution where the gain in simplicity of the model (smaller $\\boldsymbol{w}$) outweighs the cost of misclassification.\n",
    "\n",
    "**Example**:\n",
    "- Imagine a dataset with two linearly separable classes. \n",
    "- If we set $C$ to a very small value (e.g., $C = 0.01$), the SVM might prioritize a simpler model over perfectly classifying all points.\n",
    "- In this scenario, the SVM might misclassify one or more points close to the decision boundary to maintain a wider margin and a simpler hyperplane, characterized by a smaller norm of $\\boldsymbol{w}$.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dd5c7",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Classifier\n",
    "\n",
    "Alice is a cyber analyst designing a binary classifier to detect network intrusions in at a large technology company. She is considering using a decision tree (classification tree) for this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa51ec0",
   "metadata": {},
   "source": [
    "(a) In Alice’s context, what would the positive class typically refer to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4d999",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "\n",
    "\n",
    "If we let $y$ be the class label, then:\n",
    "\n",
    "- $y = 1$ (positive class) implies an intrusion is detected.\n",
    "- $y = 0$ (negative class) implies normal activity, no intrusion.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705fe2d",
   "metadata": {},
   "source": [
    "(b) Alice is considering three common approaches to measure her tree’s classification error. Briefly describe each approach, and state at least one drawback for each approach.\n",
    "\n",
    "* i. Misclassification rate \n",
    "* ii. Average loss\n",
    "* iii. Normalized negative log-likelihood (or cross-entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c3531",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "\n",
    "i. **Misclassification Rate**\n",
    "\n",
    "The misclassification rate is a straightforward measure of error. It is the proportion of the total number of predictions that were incorrect.\n",
    "\n",
    "$$\\text{Misclassification Rate} = \\frac{\\text{Number of incorrect predictions}}{\\text{Total number of predictions}}$$\n",
    "\n",
    "_Drawback_: It treats all errors equally, which might not be appropriate in contexts where the cost of false positives and false negatives is different. For example, in network intrusion detection, a false negative (failing to detect an intrusion) can be more dangerous than a false positive (wrongly detecting an intrusion).\n",
    "\n",
    "ii. **Average Loss**\n",
    "\n",
    "Average loss involves calculating the average of the loss function across all predictions. The loss function quantifies how far the predictions are from the actual values.\n",
    "\n",
    "$$\\text{Average Loss} = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, \\hat{y}_i)$$\n",
    "\n",
    "where $L(y_i, \\hat{y}_i)$ is the loss function, $y_i$ is the true label, $\\hat{y}_i$ is the predicted label, and $N$ is the number of samples.\n",
    "\n",
    "_Drawback_: The choice of loss function can significantly affect the results, and some loss functions might not be suitable for all kinds of data, especially if the data is imbalanced.\n",
    "\n",
    "iii. **Normalized Negative Log-Likelihood (or Cross-Entropy)**\n",
    "\n",
    "This approach, often used in logistic regression, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n",
    "\n",
    "$$\\text{Cross-Entropy} = - \\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(\\hat{p}_i) + (1 - y_i) \\log(1 - \\hat{p}_i)]$$\n",
    "\n",
    "where $\\hat{p}_i$ is the predicted probability of the observation belonging to the positive class.\n",
    "\n",
    "_Drawback_: It assumes the outputs of the model are probabilities, which might not always be the case, especially for some types of classifiers. Also, it can be heavily impacted by outliers or mislabeled instances.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beff2fd",
   "metadata": {},
   "source": [
    "(c) Alice is consider using a ROC (receiver operating characteristic) curve to visualize her classifier’s performance. Her colleague Bob suggests she use AUC (area under an ROC curve) to summarize each ROC into a single AUC value instead, so the AUC values may be more easily compared.\n",
    "\n",
    "i. Briefly explain why Bob’s suggestion of using AUC may be problematic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1669e5",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "\n",
    "Imbalanced Classes: If the data is highly imbalanced (i.e., the number of instances in one class significantly outweighs the number of instances in the other), the AUC might present an overly optimistic view of the model's performance. In such cases, even a poor classifier can achieve a high AUC by merely being good at distinguishing the majority class.\n",
    "\n",
    "Lack of Discrimination Between Distributions: AUC measures the model's ability to rank predictions rather than its accuracy. It doesn't distinguish between the types of errors (false positives and false negatives). Two models could have the same AUC but very different distributions of false positives and false negatives, which is crucial in applications like intrusion detection where the cost of false negatives might be much higher than false positives.\n",
    "\n",
    "No Insight into Threshold Selection: AUC doesn't provide information about the optimal threshold for classification. The ROC curve itself is a plot of the true positive rate against the false positive rate at various threshold settings, but the AUC summarizes this into one metric, losing information about which threshold might be the best for a specific operational context.\n",
    "\n",
    "Scale Insensitivity: AUC is scale-invariant, meaning it measures how well predictions are ranked rather than their absolute values. This could be a problem if the absolute values of the predictions have practical significance, which the AUC doesn't capture.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905eb645",
   "metadata": {},
   "source": [
    "ii. Alice finds that one of her trees has an AUC score of 0. Her colleague Bob notices this and is very happy with the score — why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3bfd1",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\">\n",
    "    \n",
    "0.5 indicates a model with no discriminative ability (i.e., it's as good as random guessing).\n",
    "1 indicates perfect classification.\n",
    "0 indicates the worst possible classification.\n",
    "\n",
    "An AUC score of 0 would mean that the classifier consistently classifies positive instances as negative and negative instances as positive. By simply inverting its decisions (considering its negative predictions as positive and vice versa), the model would achieve an AUC score of 1, implying perfect classification.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
